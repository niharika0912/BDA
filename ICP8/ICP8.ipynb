{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaG_rkT0Zc5p",
        "outputId": "4a816aae-78d0-4ccb-d8c8-c59c73c30507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "H-egQy0Badz2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark Context\n",
        "sc = SparkContext(\"local\", \"RDD Examples\")\n",
        "spark = SparkSession.builder.appName(\"DataFrame Examples\").getOrCreate()"
      ],
      "metadata": {
        "id": "VayHGIT1am6k"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Produce RDD with List of first 15 natural numbers\n",
        "rdd_list = sc.parallelize(range(1, 16))\n",
        "print(\"RDD with first 15 natural numbers:\", rdd_list.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8xPlRYoaq69",
        "outputId": "6dafd9cd-442d-4eec-e8b8-87ca69d17d55"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RDD with first 15 natural numbers: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Show the elements and number of partitions in RDD\n",
        "print(\"Elements in RDD:\", rdd_list.collect())\n",
        "print(\"Number of partitions:\", rdd_list.getNumPartitions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmCZw3DXay9B",
        "outputId": "770b779b-f015-499a-b5bb-c0bc69f2bc32"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elements in RDD: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "Number of partitions: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Return the first element in the RDD\n",
        "first_element = rdd_list.first()\n",
        "print(\"First element:\", first_element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPnTo-Swa6ud",
        "outputId": "e04d31e7-4197-4126-824f-d9a38872fe31"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First element: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Use filter transformation to create a new RDD by selecting even elements\n",
        "even_rdd = rdd_list.filter(lambda x: x % 2 == 0)\n",
        "print(\"Even elements:\", even_rdd.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utLM9RWJa9li",
        "outputId": "117f3371-2402-40d3-c84b-4e4ba0c9005f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Even elements: [2, 4, 6, 8, 10, 12, 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Apply map transformation to square each element in the RDD\n",
        "squared_rdd = rdd_list.map(lambda x: x ** 2)\n",
        "print(\"Squared elements:\", squared_rdd.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9VQZW2RbBtS",
        "outputId": "ca3b6de1-d5fd-4616-9330-eb8e1d7621f5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Squared elements: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Aggregate all elements in the RDD using reduce action\n",
        "sum_elements = rdd_list.reduce(lambda x, y: x + y)\n",
        "print(\"Sum of elements in RDD:\", sum_elements)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBj9D04HbEdB",
        "outputId": "35a36ac8-2596-4140-aafa-be7958a9b9e0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of elements in RDD: 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Save the RDD data as a text file\n",
        "rdd_list.saveAsTextFile(\"out_rdd_text\")"
      ],
      "metadata": {
        "id": "2mCRL98SbG4T"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Take two new list RDDs and combine them with union transformation\n",
        "rdd_list2 = sc.parallelize(range(16, 21))\n",
        "combined_rdd = rdd_list.union(rdd_list2)\n",
        "print(\"Combined RDD:\", combined_rdd.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmFmso6LbKzN",
        "outputId": "75117e50-7c16-4570-e00a-c9adbd5bbf02"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined RDD: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Use cartesian transformation to create a new list of ordered pairs\n",
        "cartesian_rdd = rdd_list.cartesian(rdd_list2)\n",
        "print(\"Cartesian product:\", cartesian_rdd.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhckNRaibQsK",
        "outputId": "528826b6-8bd8-43e6-f9a1-3fe2f0d9d25e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cartesian product: [(1, 16), (1, 17), (1, 18), (1, 19), (1, 20), (2, 16), (3, 16), (2, 17), (2, 18), (3, 17), (3, 18), (2, 19), (2, 20), (3, 19), (3, 20), (4, 16), (5, 16), (6, 16), (7, 16), (4, 17), (4, 18), (5, 17), (5, 18), (6, 17), (6, 18), (7, 17), (7, 18), (4, 19), (4, 20), (5, 19), (5, 20), (6, 19), (6, 20), (7, 19), (7, 20), (8, 16), (9, 16), (10, 16), (11, 16), (12, 16), (13, 16), (14, 16), (15, 16), (8, 17), (8, 18), (9, 17), (9, 18), (10, 17), (10, 18), (11, 17), (11, 18), (12, 17), (12, 18), (13, 17), (13, 18), (14, 17), (14, 18), (15, 17), (15, 18), (8, 19), (8, 20), (9, 19), (9, 20), (10, 19), (10, 20), (11, 19), (11, 20), (12, 19), (12, 20), (13, 19), (13, 20), (14, 19), (14, 20), (15, 19), (15, 20)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Create an RDD with Dictionary\n",
        "dict_rdd = sc.parallelize([{\"name\": \"Niharika\", \"age\": 22}, {\"name\": \"Archana\", \"age\": 21}, {\"name\": \"Sahitha\", \"age\": 20}])\n",
        "print(\"RDD with dictionary:\", dict_rdd.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-QN6-iObVHp",
        "outputId": "4d8ed404-a98c-4fd0-aa0d-6a94e0dc9bc4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RDD with dictionary: [{'name': 'Niharika', 'age': 22}, {'name': 'Archana', 'age': 21}, {'name': 'Sahitha', 'age': 20}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Get unique value in the RDD as the key and its count as the value\n",
        "rdd_flat = sc.parallelize([\"apple\", \"banana\", \"apple\", \"orange\", \"banana\", \"apple\"])\n",
        "rdd_count = rdd_flat.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y)\n",
        "print(\"Unique values and their counts:\", rdd_count.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smyar8O8bZXY",
        "outputId": "d8ea9359-3784-43de-944e-98f63eb5983c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values and their counts: [('apple', 3), ('banana', 2), ('orange', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Create RDD by combining multiple .text files\n",
        "text_rdd = sc.textFile(\"/content/drive/My Drive/sample.txt\")"
      ],
      "metadata": {
        "id": "28KzTN-UbgJQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Inspect the first 5 lines of an RDD\n",
        "print(\"First 5 lines of text RDD:\", text_rdd.take(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn3YxGhieG9J",
        "outputId": "95bae357-f03c-4e2f-98b3-be0d77a32d4b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 lines of text RDD: ['Hello, this is line 1.', 'This is line 2 of the file.', 'Line 3 goes here.', 'More data in line 4.', 'And here is line 5.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 14. Create DataFrame and Dataset\n",
        "# Import the necessary class\n",
        "from pyspark.sql import Row\n",
        "\n",
        "# Creating DataFrame from RDD\n",
        "data = [Row(name=\"Niharika\", age=22), Row(name=\"Archana\", age=21), Row(name=\"Sahitha\", age=20)]\n",
        "df = spark.createDataFrame(data)\n",
        "print(\"DataFrame:\")\n",
        "df.show()\n",
        "\n",
        "# Creating Dataset using toDF() function (PySpark doesn’t support Dataset directly)\n",
        "df_dataset = rdd_list.map(lambda x: Row(number=x)).toDF()\n",
        "print(\"Dataset equivalent in PySpark (DataFrame of single column 'number'):\")\n",
        "df_dataset.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTIRr2-od5Xx",
        "outputId": "69f2243b-011d-4b48-87b0-ca253877e5b1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame:\n",
            "+--------+---+\n",
            "|    name|age|\n",
            "+--------+---+\n",
            "|Niharika| 22|\n",
            "| Archana| 21|\n",
            "| Sahitha| 20|\n",
            "+--------+---+\n",
            "\n",
            "Dataset equivalent in PySpark (DataFrame of single column 'number'):\n",
            "+------+\n",
            "|number|\n",
            "+------+\n",
            "|     1|\n",
            "|     2|\n",
            "|     3|\n",
            "|     4|\n",
            "|     5|\n",
            "|     6|\n",
            "|     7|\n",
            "|     8|\n",
            "|     9|\n",
            "|    10|\n",
            "|    11|\n",
            "|    12|\n",
            "|    13|\n",
            "|    14|\n",
            "|    15|\n",
            "+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. Show difference between RDD, DataFrame, and Dataset\n",
        "# RDD: Basic distributed data processing API, untyped, allows any type of data\n",
        "print(\"RDD Example:\", rdd_list.collect())\n",
        "\n",
        "# DataFrame: Organized into named columns (structured data), similar to a table in SQL\n",
        "print(\"DataFrame Example:\")\n",
        "df.show()\n",
        "\n",
        "# Dataset: Only available in Scala and Java APIs in Spark, combines RDD and DataFrame features with compile-time safety\n",
        "# In PySpark, DataFrames act as a replacement for Dataset\n",
        "print(\"Dataset Example in PySpark is represented using DataFrame:\")\n",
        "df_dataset.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bxYVdiiiW4v",
        "outputId": "fd5619ef-f61b-4966-c669-ad7fea8aea2e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RDD Example: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "DataFrame Example:\n",
            "+--------+---+\n",
            "|    name|age|\n",
            "+--------+---+\n",
            "|Niharika| 22|\n",
            "| Archana| 21|\n",
            "| Sahitha| 20|\n",
            "+--------+---+\n",
            "\n",
            "Dataset Example in PySpark is represented using DataFrame:\n",
            "+------+\n",
            "|number|\n",
            "+------+\n",
            "|     1|\n",
            "|     2|\n",
            "|     3|\n",
            "|     4|\n",
            "|     5|\n",
            "|     6|\n",
            "|     7|\n",
            "|     8|\n",
            "|     9|\n",
            "|    10|\n",
            "|    11|\n",
            "|    12|\n",
            "|    13|\n",
            "|    14|\n",
            "|    15|\n",
            "+------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}