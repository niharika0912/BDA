{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLGTxoo_vK8Y",
        "outputId": "c73d0ffe-630e-486d-9c3f-f51c12a5f2fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4281 - val_loss: 0.2468\n",
            "Epoch 2/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2368 - val_loss: 0.2001\n",
            "Epoch 3/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1950 - val_loss: 0.1788\n",
            "Epoch 4/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1780 - val_loss: 0.1716\n",
            "Epoch 5/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1711 - val_loss: 0.1641\n",
            "Epoch 6/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1642 - val_loss: 0.1586\n",
            "Epoch 7/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1593 - val_loss: 0.1545\n",
            "Epoch 8/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1554 - val_loss: 0.1518\n",
            "Epoch 9/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1529 - val_loss: 0.1501\n",
            "Epoch 10/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1517 - val_loss: 0.1487\n",
            "Epoch 11/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1498 - val_loss: 0.1475\n",
            "Epoch 12/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1489 - val_loss: 0.1466\n",
            "Epoch 13/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1477 - val_loss: 0.1457\n",
            "Epoch 14/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1472 - val_loss: 0.1451\n",
            "Epoch 15/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1462 - val_loss: 0.1443\n",
            "Epoch 16/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1459 - val_loss: 0.1438\n",
            "Epoch 17/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1450 - val_loss: 0.1433\n",
            "Epoch 18/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1445 - val_loss: 0.1428\n",
            "Epoch 19/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1446 - val_loss: 0.1423\n",
            "Epoch 20/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1438 - val_loss: 0.1422\n",
            "Epoch 21/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1433 - val_loss: 0.1415\n",
            "Epoch 22/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1427 - val_loss: 0.1412\n",
            "Epoch 23/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1429 - val_loss: 0.1410\n",
            "Epoch 24/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1422 - val_loss: 0.1407\n",
            "Epoch 25/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1419 - val_loss: 0.1403\n",
            "Epoch 26/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1418 - val_loss: 0.1402\n",
            "Epoch 27/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1416 - val_loss: 0.1399\n",
            "Epoch 28/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1415 - val_loss: 0.1397\n",
            "Epoch 29/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1412 - val_loss: 0.1395\n",
            "Epoch 30/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1415 - val_loss: 0.1394\n",
            "Epoch 31/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1405 - val_loss: 0.1393\n",
            "Epoch 32/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1408 - val_loss: 0.1392\n",
            "Epoch 33/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1405 - val_loss: 0.1391\n",
            "Epoch 34/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1406 - val_loss: 0.1391\n",
            "Epoch 35/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1403 - val_loss: 0.1389\n",
            "Epoch 36/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1402 - val_loss: 0.1389\n",
            "Epoch 37/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1404 - val_loss: 0.1388\n",
            "Epoch 38/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1402 - val_loss: 0.1388\n",
            "Epoch 39/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1401 - val_loss: 0.1387\n",
            "Epoch 40/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1398 - val_loss: 0.1385\n",
            "Epoch 41/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1401 - val_loss: 0.1385\n",
            "Epoch 42/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1394 - val_loss: 0.1386\n",
            "Epoch 43/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1397 - val_loss: 0.1384\n",
            "Epoch 44/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1392 - val_loss: 0.1383\n",
            "Epoch 45/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1400 - val_loss: 0.1385\n",
            "Epoch 46/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1394 - val_loss: 0.1383\n",
            "Epoch 47/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1390 - val_loss: 0.1382\n",
            "Epoch 48/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1396 - val_loss: 0.1382\n",
            "Epoch 49/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1395 - val_loss: 0.1382\n",
            "Epoch 50/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1392 - val_loss: 0.1382\n",
            "Epoch 51/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1393 - val_loss: 0.1381\n",
            "Epoch 52/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1392 - val_loss: 0.1381\n",
            "Epoch 53/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1397 - val_loss: 0.1380\n",
            "Epoch 54/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1396 - val_loss: 0.1379\n",
            "Epoch 55/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1392 - val_loss: 0.1382\n",
            "Epoch 56/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1389 - val_loss: 0.1381\n",
            "Epoch 57/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1390 - val_loss: 0.1380\n",
            "Epoch 58/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1390 - val_loss: 0.1379\n",
            "Epoch 59/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1391 - val_loss: 0.1378\n",
            "Epoch 60/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1393 - val_loss: 0.1377\n",
            "Epoch 61/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1391 - val_loss: 0.1378\n",
            "Epoch 62/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1389 - val_loss: 0.1378\n",
            "Epoch 63/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1391 - val_loss: 0.1379\n",
            "Epoch 64/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1391 - val_loss: 0.1377\n",
            "Epoch 65/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1387 - val_loss: 0.1378\n",
            "Epoch 66/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1391 - val_loss: 0.1379\n",
            "Epoch 67/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1388 - val_loss: 0.1377\n",
            "Epoch 68/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1389 - val_loss: 0.1377\n",
            "Epoch 69/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1385 - val_loss: 0.1378\n",
            "Epoch 70/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1386 - val_loss: 0.1376\n",
            "Epoch 71/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1388 - val_loss: 0.1377\n",
            "Epoch 72/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1389 - val_loss: 0.1377\n",
            "Epoch 73/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1388 - val_loss: 0.1376\n",
            "Epoch 74/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1389 - val_loss: 0.1376\n",
            "Epoch 75/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1387 - val_loss: 0.1376\n",
            "Epoch 76/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1390 - val_loss: 0.1377\n",
            "Epoch 77/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1389 - val_loss: 0.1376\n",
            "Epoch 78/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1388 - val_loss: 0.1376\n",
            "Epoch 79/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1388 - val_loss: 0.1376\n",
            "Epoch 80/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1386 - val_loss: 0.1376\n",
            "Epoch 81/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1388 - val_loss: 0.1376\n",
            "Epoch 82/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1392 - val_loss: 0.1375\n",
            "Epoch 83/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1385 - val_loss: 0.1375\n",
            "Epoch 84/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1388 - val_loss: 0.1375\n",
            "Epoch 85/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1387 - val_loss: 0.1375\n",
            "Epoch 86/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1387 - val_loss: 0.1375\n",
            "Epoch 87/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1388 - val_loss: 0.1374\n",
            "Epoch 88/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1384 - val_loss: 0.1375\n",
            "Epoch 89/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1388 - val_loss: 0.1374\n",
            "Epoch 90/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1390 - val_loss: 0.1375\n",
            "Epoch 91/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1388 - val_loss: 0.1375\n",
            "Epoch 92/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1383 - val_loss: 0.1374\n",
            "Epoch 93/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1382 - val_loss: 0.1375\n",
            "Epoch 94/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1386 - val_loss: 0.1374\n",
            "Epoch 95/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1384 - val_loss: 0.1374\n",
            "Epoch 96/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1388 - val_loss: 0.1373\n",
            "Epoch 97/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1387 - val_loss: 0.1373\n",
            "Epoch 98/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1389 - val_loss: 0.1373\n",
            "Epoch 99/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1385 - val_loss: 0.1374\n",
            "Epoch 100/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1387 - val_loss: 0.1373\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d494ce92f80>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Flatten the images for the autoencoder\n",
        "x_train = x_train.reshape((len(x_train), -1))  # -1 infers the remaining dimension\n",
        "x_test = x_test.reshape((len(x_test), -1))  # -1 infers the remain\n",
        "\n",
        "# Define the dimensions of the input and the encoded representation\n",
        "input_dim = x_train.shape[1]\n",
        "encoding_dim = 16  # Compress to 16 features\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "# Define the encoder\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "# Adding a layer\n",
        "encoded1 = Dense(encoding_dim, activation='relu')(encoded)\n",
        "\n",
        "# Adding a layer\n",
        "decoded1 = Dense(encoding_dim, activation='relu')(encoded1)\n",
        "# Define the decoder\n",
        "decoded = Dense(input_dim, activation='sigmoid')(decoded1)\n",
        "\n",
        "# Combine the encoder and decoder into an autoencoder model\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "\n",
        "# Define EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               patience=5,  # Number of epochs with no improvement after which training will be stopped\n",
        "                               restore_best_weights=True)  # Restores model to best weights with the lowest validation loss\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(x_train, x_train,  # For autoencoders, input and output are the same\n",
        "                epochs=100,  # Set a high number of epochs\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[early_stopping])  # Add the early stopping callback"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.callbacks import TerminateOnNaN\n",
        "\n",
        "# Define the TerminateOnNaN callback\n",
        "terminate_on_nan = TerminateOnNaN()\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Flatten the images for the autoencoder\n",
        "x_train = x_train.reshape((len(x_train), -1))  # -1 infers the remaining dimension\n",
        "x_test = x_test.reshape((len(x_test), -1))  # -1 infers the remain\n",
        "\n",
        "# Define the dimensions of the input and the encoded representation\n",
        "input_dim = x_train.shape[1]\n",
        "encoding_dim = 16  # Compress to 16 features\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "# Define the encoder\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "# Adding a layer\n",
        "encoded1 = Dense(encoding_dim, activation='relu')(encoded)\n",
        "\n",
        "# Adding a layer\n",
        "decoded1 = Dense(encoding_dim, activation='relu')(encoded1)\n",
        "# Define the decoder\n",
        "decoded = Dense(input_dim, activation='sigmoid')(decoded1)\n",
        "\n",
        "# Combine the encoder and decoder into an autoencoder model\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "# Assuming x_train and x_test are your training and validation datasets\n",
        "autoencoder.fit(x_train, x_train,  # For autoencoders, input and output are the same\n",
        "                epochs=30,  # Set the number of epochs\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[terminate_on_nan])  # Add the TerminateOnNaN callback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rijxh5MHyJfG",
        "outputId": "9d4b63ca-4025-4528-8bb3-3a65cf5cb89c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.4253 - val_loss: 0.2428\n",
            "Epoch 2/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2291 - val_loss: 0.1982\n",
            "Epoch 3/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1940 - val_loss: 0.1826\n",
            "Epoch 4/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1815 - val_loss: 0.1745\n",
            "Epoch 5/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1740 - val_loss: 0.1682\n",
            "Epoch 6/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1684 - val_loss: 0.1635\n",
            "Epoch 7/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1641 - val_loss: 0.1604\n",
            "Epoch 8/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1613 - val_loss: 0.1582\n",
            "Epoch 9/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1587 - val_loss: 0.1566\n",
            "Epoch 10/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1576 - val_loss: 0.1548\n",
            "Epoch 11/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1556 - val_loss: 0.1537\n",
            "Epoch 12/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1553 - val_loss: 0.1531\n",
            "Epoch 13/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1537 - val_loss: 0.1523\n",
            "Epoch 14/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1535 - val_loss: 0.1516\n",
            "Epoch 15/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1527 - val_loss: 0.1512\n",
            "Epoch 16/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1527 - val_loss: 0.1507\n",
            "Epoch 17/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1517 - val_loss: 0.1503\n",
            "Epoch 18/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1514 - val_loss: 0.1499\n",
            "Epoch 19/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1512 - val_loss: 0.1495\n",
            "Epoch 20/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1510 - val_loss: 0.1493\n",
            "Epoch 21/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1507 - val_loss: 0.1489\n",
            "Epoch 22/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1501 - val_loss: 0.1486\n",
            "Epoch 23/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1498 - val_loss: 0.1483\n",
            "Epoch 24/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1496 - val_loss: 0.1478\n",
            "Epoch 25/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1491 - val_loss: 0.1475\n",
            "Epoch 26/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1489 - val_loss: 0.1472\n",
            "Epoch 27/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1483 - val_loss: 0.1466\n",
            "Epoch 28/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1476 - val_loss: 0.1465\n",
            "Epoch 29/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1475 - val_loss: 0.1461\n",
            "Epoch 30/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1474 - val_loss: 0.1460\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d494b362620>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint = ModelCheckpoint(filepath='autoencoder_best.keras',  # File path to save the model\n",
        "                             monitor='val_loss',  # Metric to monitor\n",
        "                             save_best_only=True,  # Save only the best model (based on the monitored metric)\n",
        "                             mode='min',  # Minimize the monitored metric (e.g., validation loss)\n",
        "                             save_weights_only=False,  # Save the entire model (set to True to save only weights)\n",
        "                             verbose=1)  # Print a message when saving the model\n",
        "\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Flatten the images for the autoencoder\n",
        "x_train = x_train.reshape((len(x_train), -1))  # -1 infers the remaining dimension\n",
        "x_test = x_test.reshape((len(x_test), -1))  # -1 infers the remain\n",
        "\n",
        "# Define the dimensions of the input and the encoded representation\n",
        "input_dim = x_train.shape[1]\n",
        "encoding_dim = 16  # Compress to 16 features\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "# Define the encoder\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "# Adding a layer\n",
        "encoded1 = Dense(encoding_dim, activation='relu')(encoded)\n",
        "\n",
        "# Adding a layer\n",
        "decoded1 = Dense(encoding_dim, activation='relu')(encoded1)\n",
        "# Define the decoder\n",
        "decoded = Dense(input_dim, activation='sigmoid')(decoded1)\n",
        "\n",
        "# Combine the encoder and decoder into an autoencoder model\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "# Assuming x_train and x_test are your training and validation datasets\n",
        "autoencoder.fit(x_train, x_train,  # For autoencoders, input and output are the same\n",
        "                epochs=30,  # Number of epochs\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),  # Validation data\n",
        "                callbacks=[checkpoint])  # Add the ModelCheckpoint callback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVf7qUrUySoO",
        "outputId": "6bf07e3a-b6a6-4c00-bf8f-268188fd4afc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4141\n",
            "Epoch 1: val_loss improved from inf to 0.24290, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.4136 - val_loss: 0.2429\n",
            "Epoch 2/30\n",
            "\u001b[1m224/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2340\n",
            "Epoch 2: val_loss improved from 0.24290 to 0.20782, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2335 - val_loss: 0.2078\n",
            "Epoch 3/30\n",
            "\u001b[1m218/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2032\n",
            "Epoch 3: val_loss improved from 0.20782 to 0.18541, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2027 - val_loss: 0.1854\n",
            "Epoch 4/30\n",
            "\u001b[1m220/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1839\n",
            "Epoch 4: val_loss improved from 0.18541 to 0.17501, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1838 - val_loss: 0.1750\n",
            "Epoch 5/30\n",
            "\u001b[1m227/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1740\n",
            "Epoch 5: val_loss improved from 0.17501 to 0.16726, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1740 - val_loss: 0.1673\n",
            "Epoch 6/30\n",
            "\u001b[1m217/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1670\n",
            "Epoch 6: val_loss improved from 0.16726 to 0.15976, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1669 - val_loss: 0.1598\n",
            "Epoch 7/30\n",
            "\u001b[1m231/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1600\n",
            "Epoch 7: val_loss improved from 0.15976 to 0.15482, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1599 - val_loss: 0.1548\n",
            "Epoch 8/30\n",
            "\u001b[1m223/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1554\n",
            "Epoch 8: val_loss improved from 0.15482 to 0.15130, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1553 - val_loss: 0.1513\n",
            "Epoch 9/30\n",
            "\u001b[1m222/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1520\n",
            "Epoch 9: val_loss improved from 0.15130 to 0.14905, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1520 - val_loss: 0.1491\n",
            "Epoch 10/30\n",
            "\u001b[1m232/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1502\n",
            "Epoch 10: val_loss improved from 0.14905 to 0.14721, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1502 - val_loss: 0.1472\n",
            "Epoch 11/30\n",
            "\u001b[1m222/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1479\n",
            "Epoch 11: val_loss improved from 0.14721 to 0.14489, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1478 - val_loss: 0.1449\n",
            "Epoch 12/30\n",
            "\u001b[1m224/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1462\n",
            "Epoch 12: val_loss improved from 0.14489 to 0.14356, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1461 - val_loss: 0.1436\n",
            "Epoch 13/30\n",
            "\u001b[1m226/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1449\n",
            "Epoch 13: val_loss improved from 0.14356 to 0.14306, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1449 - val_loss: 0.1431\n",
            "Epoch 14/30\n",
            "\u001b[1m222/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1443\n",
            "Epoch 14: val_loss improved from 0.14306 to 0.14247, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1443 - val_loss: 0.1425\n",
            "Epoch 15/30\n",
            "\u001b[1m228/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1438\n",
            "Epoch 15: val_loss improved from 0.14247 to 0.14222, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1438 - val_loss: 0.1422\n",
            "Epoch 16/30\n",
            "\u001b[1m229/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1436\n",
            "Epoch 16: val_loss improved from 0.14222 to 0.14186, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1436 - val_loss: 0.1419\n",
            "Epoch 17/30\n",
            "\u001b[1m214/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1437\n",
            "Epoch 17: val_loss improved from 0.14186 to 0.14139, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1436 - val_loss: 0.1414\n",
            "Epoch 18/30\n",
            "\u001b[1m220/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1432\n",
            "Epoch 18: val_loss improved from 0.14139 to 0.14115, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1431 - val_loss: 0.1411\n",
            "Epoch 19/30\n",
            "\u001b[1m215/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1427\n",
            "Epoch 19: val_loss improved from 0.14115 to 0.14086, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1426 - val_loss: 0.1409\n",
            "Epoch 20/30\n",
            "\u001b[1m232/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1423\n",
            "Epoch 20: val_loss improved from 0.14086 to 0.14069, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1423 - val_loss: 0.1407\n",
            "Epoch 21/30\n",
            "\u001b[1m213/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1424\n",
            "Epoch 21: val_loss improved from 0.14069 to 0.14040, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1423 - val_loss: 0.1404\n",
            "Epoch 22/30\n",
            "\u001b[1m227/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1419\n",
            "Epoch 22: val_loss improved from 0.14040 to 0.14014, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1419 - val_loss: 0.1401\n",
            "Epoch 23/30\n",
            "\u001b[1m215/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1418\n",
            "Epoch 23: val_loss improved from 0.14014 to 0.14000, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1418 - val_loss: 0.1400\n",
            "Epoch 24/30\n",
            "\u001b[1m234/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1416\n",
            "Epoch 24: val_loss improved from 0.14000 to 0.13985, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1416 - val_loss: 0.1398\n",
            "Epoch 25/30\n",
            "\u001b[1m214/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1413\n",
            "Epoch 25: val_loss improved from 0.13985 to 0.13959, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1413 - val_loss: 0.1396\n",
            "Epoch 26/30\n",
            "\u001b[1m230/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1409\n",
            "Epoch 26: val_loss improved from 0.13959 to 0.13939, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1409 - val_loss: 0.1394\n",
            "Epoch 27/30\n",
            "\u001b[1m226/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1405\n",
            "Epoch 27: val_loss improved from 0.13939 to 0.13906, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1405 - val_loss: 0.1391\n",
            "Epoch 28/30\n",
            "\u001b[1m230/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1408\n",
            "Epoch 28: val_loss improved from 0.13906 to 0.13885, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1408 - val_loss: 0.1389\n",
            "Epoch 29/30\n",
            "\u001b[1m216/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1403\n",
            "Epoch 29: val_loss improved from 0.13885 to 0.13849, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1403 - val_loss: 0.1385\n",
            "Epoch 30/30\n",
            "\u001b[1m212/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1400\n",
            "Epoch 30: val_loss improved from 0.13849 to 0.13818, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1399 - val_loss: 0.1382\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d494c348460>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Define the ReduceLROnPlateau callback\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',  # Metric to monitor\n",
        "                              factor=0.5,  # Factor by which the learning rate will be reduced (new_lr = lr * factor)\n",
        "                              patience=3,  # Number of epochs with no improvement after which learning rate will be reduced\n",
        "                              min_lr=1e-6,  # Lower bound for the learning rate\n",
        "                              verbose=1)  # Print message when the learning rate is reduced\n",
        "\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Flatten the images for the autoencoder\n",
        "x_train = x_train.reshape((len(x_train), -1))  # -1 infers the remaining dimension\n",
        "x_test = x_test.reshape((len(x_test), -1))  # -1 infers the remain\n",
        "\n",
        "# Define the dimensions of the input and the encoded representation\n",
        "input_dim = x_train.shape[1]\n",
        "encoding_dim = 16  # Compress to 16 features\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "# Define the encoder\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "# Adding a layer\n",
        "encoded1 = Dense(encoding_dim, activation='relu')(encoded)\n",
        "\n",
        "# Adding a layer\n",
        "decoded1 = Dense(encoding_dim, activation='relu')(encoded1)\n",
        "# Define the decoder\n",
        "decoded = Dense(input_dim, activation='sigmoid')(decoded1)\n",
        "\n",
        "# Combine the encoder and decoder into an autoencoder model\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "# Assuming x_train and x_test are your training and validation datasets\n",
        "autoencoder.fit(x_train, x_train,  # For autoencoders, input and output are the same\n",
        "                epochs=30,  # Number of epochs\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),  # Validation data\n",
        "                callbacks=[reduce_lr])  # Add the ReduceLROnPlateau callback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E7z1-ppyc3N",
        "outputId": "f82e1523-60b2-41cc-a035-3d18f3e8e937"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.4440 - val_loss: 0.2502 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2436 - val_loss: 0.2274 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2260 - val_loss: 0.2078 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2036 - val_loss: 0.1901 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1883 - val_loss: 0.1777 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1771 - val_loss: 0.1708 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1712 - val_loss: 0.1674 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1679 - val_loss: 0.1654 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1665 - val_loss: 0.1641 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1652 - val_loss: 0.1629 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1640 - val_loss: 0.1623 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1634 - val_loss: 0.1615 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1627 - val_loss: 0.1610 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1622 - val_loss: 0.1607 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1618 - val_loss: 0.1603 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1616 - val_loss: 0.1596 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1608 - val_loss: 0.1590 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1601 - val_loss: 0.1587 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1597 - val_loss: 0.1583 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1597 - val_loss: 0.1582 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1592 - val_loss: 0.1580 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1594 - val_loss: 0.1577 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1589 - val_loss: 0.1575 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1591 - val_loss: 0.1574 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1586 - val_loss: 0.1572 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1589 - val_loss: 0.1571 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1581 - val_loss: 0.1571 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1579 - val_loss: 0.1570 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1580 - val_loss: 0.1569 - learning_rate: 0.0010\n",
            "Epoch 30/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1581 - val_loss: 0.1568 - learning_rate: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d494cd07d90>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TerminateOnNaN, ReduceLROnPlateau\n",
        "\n",
        "# EarlyStopping callback to stop training if validation loss stops improving\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# ModelCheckpoint callback to save the best model based on validation loss\n",
        "checkpoint = ModelCheckpoint(filepath='autoencoder_best.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "# TerminateOnNaN callback to stop training if the loss becomes NaN\n",
        "terminate_on_nan = TerminateOnNaN()\n",
        "\n",
        "# Define the ReduceLROnPlateau callback\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,   patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Flatten the images for the autoencoder\n",
        "x_train = x_train.reshape((len(x_train), -1))  # -1 infers the remaining dimension\n",
        "x_test = x_test.reshape((len(x_test), -1))  # -1 infers the remain\n",
        "\n",
        "# Define the dimensions of the input and the encoded representation\n",
        "input_dim = x_train.shape[1]\n",
        "encoding_dim = 16  # Compress to 16 features\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "# Define the encoder\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "# Adding a layer\n",
        "encoded1 = Dense(encoding_dim, activation='relu')(encoded)\n",
        "\n",
        "# Adding a layer\n",
        "decoded1 = Dense(encoding_dim, activation='relu')(encoded1)\n",
        "# Define the decoder\n",
        "decoded = Dense(input_dim, activation='sigmoid')(decoded1)\n",
        "\n",
        "# Combine the encoder and decoder into an autoencoder model\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Training with multiple callbacks\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=30,  # You can set a high number of epochs\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[reduce_lr, early_stopping, checkpoint, terminate_on_nan])  # Using multiple callbacks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWueso0LyloY",
        "outputId": "4ab91d50-fef3-4e60-9665-c133c6b1ff42"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4149\n",
            "Epoch 1: val_loss improved from inf to 0.23882, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.4145 - val_loss: 0.2388 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m233/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2269\n",
            "Epoch 2: val_loss improved from 0.23882 to 0.19598, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2268 - val_loss: 0.1960 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m232/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1930\n",
            "Epoch 3: val_loss improved from 0.19598 to 0.18051, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1930 - val_loss: 0.1805 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m229/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1794\n",
            "Epoch 4: val_loss improved from 0.18051 to 0.17072, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1793 - val_loss: 0.1707 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m212/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1712\n",
            "Epoch 5: val_loss improved from 0.17072 to 0.16554, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1710 - val_loss: 0.1655 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m218/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1660\n",
            "Epoch 6: val_loss improved from 0.16554 to 0.16209, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1659 - val_loss: 0.1621 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m227/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1625\n",
            "Epoch 7: val_loss improved from 0.16209 to 0.15862, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1625 - val_loss: 0.1586 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m223/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1596\n",
            "Epoch 8: val_loss improved from 0.15862 to 0.15637, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1596 - val_loss: 0.1564 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m216/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1578\n",
            "Epoch 9: val_loss improved from 0.15637 to 0.15509, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1578 - val_loss: 0.1551 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m225/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1561\n",
            "Epoch 10: val_loss improved from 0.15509 to 0.15389, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1561 - val_loss: 0.1539 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m219/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1549\n",
            "Epoch 11: val_loss improved from 0.15389 to 0.15318, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1549 - val_loss: 0.1532 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m218/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1545\n",
            "Epoch 12: val_loss improved from 0.15318 to 0.15259, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1545 - val_loss: 0.1526 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m227/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1533\n",
            "Epoch 13: val_loss improved from 0.15259 to 0.15075, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1533 - val_loss: 0.1508 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m224/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1519\n",
            "Epoch 14: val_loss improved from 0.15075 to 0.15007, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1519 - val_loss: 0.1501 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1513\n",
            "Epoch 15: val_loss improved from 0.15007 to 0.14924, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1513 - val_loss: 0.1492 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m221/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1505\n",
            "Epoch 16: val_loss improved from 0.14924 to 0.14890, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1505 - val_loss: 0.1489 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m234/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1500\n",
            "Epoch 17: val_loss improved from 0.14890 to 0.14831, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1500 - val_loss: 0.1483 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m221/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1497\n",
            "Epoch 18: val_loss improved from 0.14831 to 0.14787, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1497 - val_loss: 0.1479 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m213/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1490\n",
            "Epoch 19: val_loss improved from 0.14787 to 0.14753, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1490 - val_loss: 0.1475 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m231/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1490\n",
            "Epoch 20: val_loss improved from 0.14753 to 0.14727, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1490 - val_loss: 0.1473 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m232/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1482\n",
            "Epoch 21: val_loss improved from 0.14727 to 0.14692, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1482 - val_loss: 0.1469 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m223/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1485\n",
            "Epoch 22: val_loss improved from 0.14692 to 0.14667, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1485 - val_loss: 0.1467 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m219/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1483\n",
            "Epoch 23: val_loss improved from 0.14667 to 0.14637, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1483 - val_loss: 0.1464 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m220/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1477\n",
            "Epoch 24: val_loss improved from 0.14637 to 0.14622, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1477 - val_loss: 0.1462 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m211/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1475\n",
            "Epoch 25: val_loss improved from 0.14622 to 0.14576, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1474 - val_loss: 0.1458 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m222/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1472\n",
            "Epoch 26: val_loss improved from 0.14576 to 0.14561, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1472 - val_loss: 0.1456 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m230/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1469\n",
            "Epoch 27: val_loss improved from 0.14561 to 0.14514, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1469 - val_loss: 0.1451 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m226/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1465\n",
            "Epoch 28: val_loss improved from 0.14514 to 0.14481, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1465 - val_loss: 0.1448 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m232/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1462\n",
            "Epoch 29: val_loss improved from 0.14481 to 0.14464, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1462 - val_loss: 0.1446 - learning_rate: 0.0010\n",
            "Epoch 30/30\n",
            "\u001b[1m227/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1460\n",
            "Epoch 30: val_loss improved from 0.14464 to 0.14433, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1460 - val_loss: 0.1443 - learning_rate: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d494c99d000>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the entire model\n",
        "best_autoencoder = load_model('autoencoder_best.keras')\n",
        "\n",
        "# Let's look at the encoded representations\n",
        "encoded_data = best_autoencoder.predict(x_test)\n",
        "print(encoded_data)\n",
        "print(encoded_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7rk91Y4yvR-",
        "outputId": "235f3412-aa92-49e8-f0ef-ea35c864a97b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "[[1.7018325e-08 7.2681594e-08 3.5119115e-08 ... 3.3727294e-09\n",
            "  3.5735695e-08 3.7971006e-08]\n",
            " [1.9233273e-11 3.3901573e-12 5.2530220e-12 ... 3.2635377e-11\n",
            "  5.0725816e-11 8.5806653e-11]\n",
            " [2.5992082e-07 5.8565831e-07 3.0234207e-07 ... 2.9380675e-07\n",
            "  3.0333968e-07 4.3552456e-07]\n",
            " ...\n",
            " [2.1001959e-12 1.8659731e-12 8.6227716e-13 ... 1.0330165e-13\n",
            "  7.7334033e-12 5.8534896e-12]\n",
            " [3.1636964e-11 4.1543831e-11 1.4608087e-11 ... 2.6394126e-11\n",
            "  1.2884299e-10 2.5476751e-10]\n",
            " [1.3220716e-18 5.4016445e-21 8.4519473e-20 ... 1.9753120e-20\n",
            "  4.9341939e-19 3.4334077e-18]]\n",
            "(10000, 784)\n"
          ]
        }
      ]
    }
  ]
}